# ==============================================================================
# Code Cache Manager - ä»£ç ç¼“å­˜å¤ç”¨ç³»ç»Ÿ
# ==============================================================================
# æ ¸å¿ƒåŠŸèƒ½ï¼š
# 1. å°†æˆåŠŸæ‰§è¡Œçš„ä»£ç å­˜å…¥ Milvus å‘é‡åº“
# 2. æ ¹æ®ä»»åŠ¡æè¿° + DOM ç»“æ„æ£€ç´¢ç›¸ä¼¼ä»£ç 
# 3. å¤ç”¨å†å²ä»£ç ï¼Œå‡å°‘ Token æ¶ˆè€—
# ==============================================================================

import hashlib
import re
import atexit
from typing import List, Dict, Any, Optional, NamedTuple
from datetime import datetime
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor

from langchain_milvus import Milvus
from langchain_core.documents import Document

from config import CODE_COLLECTION_NAME


class CacheHit(NamedTuple):
    """ç¼“å­˜å‘½ä¸­ç»“æœ"""
    id: str
    code: str
    score: float
    url_pattern: str
    goal: str  # [V4] æ”¹ä¸º goal
    success_count: int
    user_task: str = ""  # [V5] åŸå§‹ç”¨æˆ·ä»»åŠ¡


# ==============================================================================
# [V5] å‚æ•° Diff + æ›¿æ¢å·¥å…·å‡½æ•°
# ==============================================================================

def extract_param_diffs(cached_task: str, current_task: str) -> list:
    """
    å¯¹æ¯”ä¸¤ä¸ª taskï¼Œæå–å˜åŒ–çš„"å‚æ•°"éƒ¨åˆ†ã€‚

    ä½¿ç”¨ token çº§ SequenceMatcher diffï¼š
    1. å…ˆç”¨æ­£åˆ™å°†æ–‡æœ¬åˆ‡åˆ†ä¸º tokenï¼ˆè‹±æ–‡å•è¯/æ•°å­—ä¿æŒå®Œæ•´ï¼Œå…¶ä½™é€å­—ç¬¦ï¼‰
    2. å¯¹ token åºåˆ—åš diffï¼Œæå– replace æ“ä½œ
    3. å°†æ›¿æ¢çš„ token ç»„æ‹¼å›å­—ç¬¦ä¸²ï¼Œä½œä¸ºå‚æ•°å·®å¼‚

    èƒ½æ­£ç¡®å¤„ç†ä¸­æ–‡ã€æ··åˆè¯­è¨€ç­‰æ— ç©ºæ ¼æ–‡æœ¬ã€‚
    æŒ‰æ—§å‚æ•°é•¿åº¦é™åºæ’åˆ—ï¼ˆé˜²æ­¢çŸ­ä¸²è¯¯æ›¿æ¢é•¿ä¸²çš„å­ä¸²ï¼‰ã€‚
    """
    import difflib
    import re as _re

    def _tokenize(text: str) -> list:
        """è¿ç»­è‹±æ–‡/æ•°å­—ä¸ºä¸€ä¸ª tokenï¼Œå…¶ä½™æ¯ä¸ªéç©ºå­—ç¬¦ä¸ºä¸€ä¸ª token"""
        return _re.findall(r'[a-zA-Z0-9_]+|\S', text)

    old_tokens = _tokenize(cached_task)
    new_tokens = _tokenize(current_task)

    matcher = difflib.SequenceMatcher(None, old_tokens, new_tokens)
    diffs = []

    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'replace':
            old_val = ''.join(old_tokens[i1:i2])
            new_val = ''.join(new_tokens[j1:j2])
            if len(old_val) >= 2 and len(new_val) >= 2:
                diffs.append((old_val, new_val))

    # æŒ‰æ—§å‚æ•°é•¿åº¦é™åºæ’åˆ—ï¼Œé˜²æ­¢ "fish" åœ¨ "fishery" ä¹‹å‰è¢«æ›¿æ¢
    diffs.sort(key=lambda x: len(x[0]), reverse=True)
    return diffs


def apply_param_substitution(code: str, diffs: list) -> str:
    """
    åœ¨ä»£ç çš„å­—ç¬¦ä¸²å­—é¢é‡ä¸­æ›¿æ¢å‚æ•°ï¼ˆé›¶ LLM Tokenï¼‰
    åªæ›¿æ¢å¼•å·å†…çš„å†…å®¹ï¼Œé¿å…è¯¯æ”¹å˜é‡å/å‡½æ•°å
    """
    import re as _re
    for old_val, new_val in diffs:
        # åŒ¹é…å•å¼•å·æˆ–åŒå¼•å·å†…åŒ…å« old_val çš„å­—ç¬¦ä¸²
        pattern = _re.compile(
            r"""(['"])([^'"]*?)""" + _re.escape(old_val) + r"""([^'"]*?)\1"""
        )
        code = pattern.sub(
            lambda m: f"{m.group(1)}{m.group(2)}{new_val}{m.group(3)}{m.group(1)}",
            code
        )
    return code


class CodeCacheManager:
    """
    ä»£ç ç¼“å­˜ç®¡ç†å™¨

    å­˜å‚¨ç­–ç•¥ï¼š
    - ä»…å­˜å‚¨éªŒè¯é€šè¿‡çš„ä»£ç 
    - å‘é‡åŒ–: goal + url_pattern + dom_skeleton[:2500]
    - è¾…åŠ©åŒ¹é…: url_pattern + dom_hash
    """

    SIMILARITY_THRESHOLD = 0.9
    DOM_MAX_LENGTH = 2500
    MAX_EMBEDDING_CHARS = 4000  # [V4] Embedding è¾“å…¥æœ€å¤§å­—ç¬¦æ•°
    MAX_CODE_WARN = 4000  # [V4] ä»£ç è¶…è¿‡æ­¤é•¿åº¦è¾“å‡ºè­¦å‘Š

    def __init__(self):
        self._vector_store: Optional[Milvus] = None
        self._embeddings = None
        # [V5] å¼‚æ­¥å­˜å‚¨çº¿ç¨‹æ± ï¼ˆå•çº¿ç¨‹ä¿è¯é¡ºåºï¼‰
        self._executor = ThreadPoolExecutor(
            max_workers=1, thread_name_prefix="CodeCache")
        # ç¨‹åºé€€å‡ºæ—¶ç­‰å¾…ä»»åŠ¡å®Œæˆ
        atexit.register(self._shutdown)

    def _get_embeddings(self):
        """æ‡’åŠ è½½ Embedding æ¨¡å‹"""
        if self._embeddings is None:
            from rag.retriever_qa import get_embedding_model
            self._embeddings = get_embedding_model()
        return self._embeddings

    def _get_vector_store(self) -> Milvus:
        """æ‡’åŠ è½½ Milvus è¿æ¥"""
        if self._vector_store is None:
            from config import MILVUS_URI

            # ä½¿ç”¨ COSINE ç›¸ä¼¼åº¦ï¼ˆè¿”å›å€¼èŒƒå›´ 0~1ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼ï¼‰
            index_params = {
                "metric_type": "COSINE",
                "index_type": "AUTOINDEX",
            }

            self._vector_store = Milvus(
                embedding_function=self._get_embeddings(),
                connection_args={"uri": MILVUS_URI},
                collection_name=CODE_COLLECTION_NAME,
                index_params=index_params,
                consistency_level="Bounded",
                auto_id=True,
                enable_dynamic_field=True,  # [V5] å¯ç”¨åŠ¨æ€å­—æ®µï¼Œå…è®¸å­˜å‚¨ user_task ç­‰æ–°å­—æ®µ
            )
        return self._vector_store

    # ========== è¾…åŠ©æ–¹æ³• ==========

    def _normalize_url(self, url: str) -> str:
        """
        URL å½’ä¸€åŒ–ï¼šæå–åŸŸå + è·¯å¾„æ¨¡å¼ï¼Œå»é™¤åŠ¨æ€å‚æ•°

        Example:
            https://item.taobao.com/item.htm?id=123&spm=xxx
            -> taobao.com/item.htm
        """
        try:
            parsed = urlparse(url)
            # æå–ä¸»åŸŸå (å»æ‰ www. å’Œå­åŸŸå)
            domain_parts = parsed.netloc.split('.')
            if len(domain_parts) >= 2:
                domain = '.'.join(domain_parts[-2:])
            else:
                domain = parsed.netloc

            # æ¸…ç†è·¯å¾„ï¼šå»é™¤æ•°å­— IDï¼Œä¿ç•™ç»“æ„
            path = parsed.path
            # å°†è¿ç»­æ•°å­—æ›¿æ¢ä¸º *
            path = re.sub(r'/\d+', '/*', path)

            return f"{domain}{path}"
        except Exception:
            return url

    def _compute_dom_hash(self, dom_skeleton: str) -> str:
        """è®¡ç®— DOM ç»“æ„å“ˆå¸Œ"""
        # ä½¿ç”¨å‰ 2500 å­—ç¬¦è®¡ç®— MD5
        content = dom_skeleton[:self.DOM_MAX_LENGTH] if dom_skeleton else ""
        return hashlib.md5(content.encode('utf-8')).hexdigest()[:16]

    def _build_embedding_text(self, goal: str, url: str, user_task: str = "", locator_info: str = "") -> str:
        """æ„å»ºç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬ [V5] ç§»é™¤ DOMï¼Œæ”¹ç”¨ Task + Goal + URL + Locator æ‘˜è¦"""
        url_pattern = self._normalize_url(url)

        parts = []
        if user_task:
            parts.append(f"Task: {user_task}")
        parts.append(f"Goal: {goal}" * 5)
        parts.append(f"URL: {url_pattern}")
        if locator_info:
            parts.append(f"Locators: {locator_info[:800]}")
        text = "\n".join(parts)

        # æˆªæ–­ä¿æŠ¤
        if len(text) > self.MAX_EMBEDDING_CHARS:
            text = text[:self.MAX_EMBEDDING_CHARS]
            print(
                f"âš ï¸ [CodeCache] Embedding è¾“å…¥æˆªæ–­è‡³ {self.MAX_EMBEDDING_CHARS} chars")

        return text

    # ========== æ ¸å¿ƒ API ==========

    def search(
        self,
        user_task: str,
        goal: str,
        url: str,
        locator_info: str = "",
        top_k: int = 3
    ) -> List[CacheHit]:
        """
        æ£€ç´¢ç›¸ä¼¼ä»£ç 

        Args:
            task: ç”¨æˆ·ä»»åŠ¡æè¿°
            url: å½“å‰é¡µé¢ URL
            locator_info: Observer çš„å®šä½ç­–ç•¥æ‘˜è¦
            top_k: è¿”å›æ•°é‡

        Returns:
            List[CacheHit]: æŒ‰ç›¸ä¼¼åº¦æ’åºçš„ç¼“å­˜å‘½ä¸­åˆ—è¡¨
        """
        print(f"ğŸ” [CodeCache] Searching for similar code...")

        try:
            vector_store = self._get_vector_store()

            # æ„å»ºæ£€ç´¢æ–‡æœ¬
            query_text = self._build_embedding_text(
                goal, url, user_task, locator_info)

            # å‘é‡æ£€ç´¢
            results = vector_store.similarity_search_with_score(
                query=query_text,
                k=top_k
            )

            hits = []
            for doc, score in results:
                # COSINE ç›¸ä¼¼åº¦ï¼šscore èŒƒå›´ 0~1ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼
                similarity = score

                if similarity >= self.SIMILARITY_THRESHOLD:
                    hit = CacheHit(
                        id=doc.metadata.get("cache_id", ""),
                        code=doc.metadata.get("code", ""),
                        score=similarity,
                        url_pattern=doc.metadata.get("url_pattern", ""),
                        goal=doc.metadata.get("goal", ""),
                        success_count=doc.metadata.get("success_count", 0),
                        user_task=doc.metadata.get("user_task", ""),  # [V5]
                    )
                    hits.append(hit)

            if hits:
                print(
                    f"âœ… Found {len(hits)} cache hits (best score: {hits[0].score:.4f})")
            else:
                print(
                    f"âŒ No cache hit above threshold ({self.SIMILARITY_THRESHOLD})")

            return hits

        except Exception as e:
            print(f"âš ï¸ [CodeCache] Search error: {e}")
            return []

    # å¯¼èˆªç±»ä»£ç çš„æœ€å¤§é•¿åº¦é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤é•¿åº¦è®¤ä¸ºä¸æ˜¯çº¯å¯¼èˆªä»£ç ï¼‰
    NAVIGATION_CODE_MAX_LENGTH = 200

    # å»é‡ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆå­˜å‚¨å‰æ£€æŸ¥ï¼‰
    DUPLICATE_THRESHOLD = 0.90

    def _is_navigation_task(self, goal: str, code: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºçº¯å¯¼èˆª/è·³è½¬ç±»ä»£ç ï¼ˆåº”è·³è¿‡å­˜å‚¨ï¼‰

        åˆ¤æ–­æ ‡å‡†ï¼šä»£ç å¾ˆçŸ­ ä¸” ä¸»è¦æ˜¯ tab.get() è°ƒç”¨
        """
        # ä»£ç è¾ƒé•¿ï¼Œä¸å¯èƒ½æ˜¯çº¯å¯¼èˆª
        if len(code) > self.NAVIGATION_CODE_MAX_LENGTH:
            return False

        # æ£€æŸ¥ä»£ç å†…å®¹ï¼šå¦‚æœä¸»è¦æ˜¯ tab.get() è°ƒç”¨
        code_lower = code.lower().strip()
        navigation_patterns = ["tab.get(", "tab.get ("]

        for pattern in navigation_patterns:
            if pattern in code_lower:
                # ç»Ÿè®¡ä»£ç è¡Œæ•°ï¼ˆå»æ‰ç©ºè¡Œå’Œ printï¼‰
                meaningful_lines = [
                    line for line in code.split('\n')
                    if line.strip() and not line.strip().startswith('print')
                ]
                # å¦‚æœæœ‰æ„ä¹‰çš„ä»£ç è¡Œ <= 3 è¡Œï¼Œè®¤ä¸ºæ˜¯çº¯å¯¼èˆª
                if len(meaningful_lines) <= 3:
                    return True

        return False

    def _is_duplicate(self, goal: str, dom_skeleton: str, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸å·²å­˜å‚¨å†…å®¹é‡å¤ï¼ˆç›¸ä¼¼åº¦ >= 90%ï¼‰"""
        try:
            vector_store = self._get_vector_store()
            query_text = self._build_embedding_text(goal, dom_skeleton, url)

            results = vector_store.similarity_search_with_score(
                query=query_text, k=1)

            if results:
                _, score = results[0]
                if score >= self.DUPLICATE_THRESHOLD:
                    print(
                        f"   âš ï¸ [CodeCache] ç›¸ä¼¼å†…å®¹å·²å­˜åœ¨ (score={score:.4f} >= {self.DUPLICATE_THRESHOLD})ï¼Œè·³è¿‡å­˜å‚¨")
                    return True
            return False
        except Exception as e:
            print(f"âš ï¸ [CodeCache] Duplicate check error: {e}")
            return False  # æ£€æŸ¥å¤±è´¥æ—¶å…è®¸å­˜å‚¨

    def _shutdown(self):
        """å…³é—­çº¿ç¨‹æ± ï¼Œç­‰å¾…ä»»åŠ¡å®Œæˆ"""
        print("ğŸ”„ [CodeCache] ç­‰å¾…åå°å­˜å‚¨ä»»åŠ¡å®Œæˆ...")
        self._executor.shutdown(wait=True)
        print("âœ… [CodeCache] åå°ä»»åŠ¡å·²å®Œæˆ")

    def _do_save_async(self, goal: str, dom_skeleton: str, url: str, code: str, user_task: str = "", locator_info: str = ""):
        """
        åå°æ‰§è¡Œçš„å­˜å‚¨é€»è¾‘ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰
        åŒ…å«ï¼šå»é‡æ£€æŸ¥ + å®é™…å­˜å‚¨
        """
        try:
            # å»é‡æ£€æŸ¥ï¼ˆè€—æ—¶æ“ä½œï¼Œç°åœ¨åœ¨åå°æ‰§è¡Œï¼‰
            if self._is_duplicate(goal, dom_skeleton, url):
                return

            vector_store = self._get_vector_store()

            # æ„å»ºå…ƒæ•°æ®
            url_pattern = self._normalize_url(url)
            dom_hash = self._compute_dom_hash(dom_skeleton)
            cache_id = f"{dom_hash}_{datetime.now().strftime('%Y%m%d%H%M%S')}"

            metadata = {
                "cache_id": cache_id,
                "url_pattern": url_pattern,
                "dom_hash": dom_hash,
                "goal": goal,
                "user_task": user_task,  # [V5] å­˜å‚¨åŸå§‹ç”¨æˆ·ä»»åŠ¡
                "code": code,
                "code_length": len(code),
                "success_count": 1,
                "fail_count": 0,
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
            }

            # æ„å»ºå‘é‡åŒ–æ–‡æœ¬ï¼ˆä¸å†ä½¿ç”¨ DOMï¼Œæ”¹ç”¨ locator_infoï¼‰
            embedding_text = self._build_embedding_text(
                goal, url, user_task=user_task, locator_info=locator_info)

            # åˆ›å»º Document å¹¶å­˜å‚¨
            doc = Document(page_content=embedding_text, metadata=metadata)
            vector_store.add_documents([doc])

            print(f"   âœ… [CodeCache] åå°å­˜å‚¨å®Œæˆ: {cache_id}")

        except Exception as e:
            print(f"âŒ [CodeCache] åå°å­˜å‚¨å¤±è´¥: {e}")

    def save(
        self,
        goal: str,
        dom_skeleton: str,
        url: str,
        code: str,
        user_task: str = "",
        locator_info: str = ""
    ) -> None:
        """
        å¼‚æ­¥å­˜å‚¨æˆåŠŸæ‰§è¡Œçš„ä»£ç ï¼ˆéé˜»å¡ï¼‰

        Args:
            goal: å½“å‰æ­¥éª¤ç›®æ ‡
            dom_skeleton: DOM éª¨æ¶ï¼ˆä»…ç”¨äºå»é‡ hashï¼‰
            url: å½“å‰é¡µé¢ URL
            code: ç”Ÿæˆçš„ä»£ç 
            user_task: åŸå§‹ç”¨æˆ·ä»»åŠ¡ï¼ˆç”¨äºå‚æ•°æ„ŸçŸ¥å¤ç”¨ï¼‰
            locator_info: Observer çš„å®šä½ç­–ç•¥æ‘˜è¦ï¼ˆç”¨äº embeddingï¼‰

        Note:
            æ­¤æ–¹æ³•ç«‹å³è¿”å›ï¼Œå®é™…å­˜å‚¨åœ¨åå°çº¿ç¨‹æ‰§è¡Œ
        """
        # ========== åŒæ­¥è¿‡æ»¤ï¼ˆè½»é‡çº§ï¼Œç«‹å³æ‰§è¡Œï¼‰==========

        # è¿‡æ»¤: è·³è¿‡çº¯å¯¼èˆªç±»ä»£ç ï¼ˆçŸ­ä»£ç  + åªæœ‰ tab.getï¼‰
        if self._is_navigation_task(goal, code):
            print(f"â­ï¸ [CodeCache] è·³è¿‡çº¯å¯¼èˆªä»£ç  ({len(code)} chars)")
            return False

        # è¶…é•¿ä»£ç è­¦å‘Š
        if len(code) > self.MAX_CODE_WARN:
            print(f"âš ï¸ [CodeCache] ä»£ç è¾ƒé•¿ ({len(code)} chars)ï¼Œå»ºè®® Planner æ‹†åˆ†ä»»åŠ¡")

        # ========== å¼‚æ­¥å­˜å‚¨ï¼ˆæäº¤åˆ°åå°çº¿ç¨‹ï¼‰==========
        print(f"ğŸ“¤ [CodeCache] æäº¤åå°å­˜å‚¨ä»»åŠ¡ (code: {len(code)} chars)")
        self._executor.submit(self._do_save_async, goal,
                              dom_skeleton, url, code, user_task, locator_info)
        return True

    def update_stats(self, cache_id: str, success: bool) -> bool:
        """
        æ›´æ–°æ‰§è¡Œç»Ÿè®¡

        æ³¨æ„ï¼šMilvus ä¸æ”¯æŒç›´æ¥æ›´æ–°ï¼Œéœ€è¦åˆ é™¤åé‡æ–°æ’å…¥
        è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªæ‰“å°æ—¥å¿—
        """
        action = "success" if success else "fail"
        print(f"ğŸ“Š [CodeCache] Recording {action} for cache_id: {cache_id}")
        # TODO: å®ç°çœŸæ­£çš„ç»Ÿè®¡æ›´æ–° (éœ€è¦è¯»å– -> ä¿®æ”¹ -> é‡æ–°æ’å…¥)
        return True


# å•ä¾‹æ¨¡å¼
code_cache_manager = CodeCacheManager()
