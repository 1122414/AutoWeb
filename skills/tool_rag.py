"""
AutoWeb çŸ¥è¯†åº“ç®¡ç†å™¨
====================
åŠŸèƒ½ï¼š
- å•ä¾‹æ¨¡å¼ç®¡ç† Milvus è¿æ¥å’Œ Embedding æ¨¡å‹
- ç¼“å†²é˜Ÿåˆ— + æ‰¹é‡å¼‚æ­¥å†™å…¥
- ç¨‹åºé€€å‡ºæ—¶åŒæ­¥åˆ·æ–°
"""
import sys
import os
import atexit
from typing import List, Dict, Union, Optional
from concurrent.futures import ThreadPoolExecutor, Future
from threading import Lock

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ path ä¸­
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class KnowledgeBaseManager:
    """
    çŸ¥è¯†åº“ç®¡ç†å™¨ï¼ˆå•ä¾‹ï¼‰

    ä½¿ç”¨æ–¹å¼:
        from skills.tool_rag import kb_manager
        kb_manager.add("çˆ¬å–çš„æ–‡æœ¬å†…å®¹", source="https://example.com")
        kb_manager.flush_and_wait()  # ç¨‹åºé€€å‡ºå‰è°ƒç”¨
    """
    _instance: Optional['KnowledgeBaseManager'] = None
    _initialized: bool = False

    # é…ç½®
    BUFFER_THRESHOLD = 10  # ç¼“å†²åŒºé˜ˆå€¼ï¼Œè¾¾åˆ°åè‡ªåŠ¨åˆ·æ–°
    MAX_CONTENT_LENGTH = 5000  # å•æ¡å†…å®¹æœ€å¤§é•¿åº¦

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if KnowledgeBaseManager._initialized:
            return
        KnowledgeBaseManager._initialized = True

        self.buffer: List = []  # å¾…å†™å…¥çš„æ–‡æ¡£ç¼“å†²
        self.lock = Lock()  # çº¿ç¨‹å®‰å…¨é”
        self.executor = ThreadPoolExecutor(
            max_workers=1, thread_name_prefix="kb_writer")
        self.pending_futures: List[Future] = []  # è·Ÿè¸ªå¼‚æ­¥ä»»åŠ¡

        # å»¶è¿Ÿåˆå§‹åŒ–ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶æ‰è¿æ¥ï¼‰
        self._embeddings = None
        self._vector_store = None

        # æ³¨å†Œç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°
        atexit.register(self._cleanup)

        print("ğŸ“š [KnowledgeBaseManager] åˆå§‹åŒ–å®Œæˆï¼ˆå»¶è¿ŸåŠ è½½æ¨¡å¼ï¼‰")

    def _ensure_connection(self):
        """ç¡®ä¿è¿æ¥å·²å»ºç«‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if self._embeddings is None:
            print("ğŸ”Œ [KnowledgeBaseManager] å»ºç«‹ Embedding å’Œ Milvus è¿æ¥...")
            try:
                from config import MILVUS_URI
                from rag.retriever_qa import get_embedding_model
                from rag.milvus_schema import get_vector_store
                from skills.vector_gateway import connect_milvus

                connect_milvus(MILVUS_URI, alias="default",
                               tag="KnowledgeBaseManager")
                self._embeddings = get_embedding_model()
                self._vector_store = get_vector_store(self._embeddings)
                print("   âœ… è¿æ¥å»ºç«‹æˆåŠŸï¼ˆSchema å·²éªŒè¯ï¼‰")
            except Exception as e:
                print(f"   âŒ è¿æ¥å¤±è´¥: {e}")
                raise

    # é«˜é¢‘å­—æ®µååˆ—è¡¨ï¼ˆä¸ milvus_schema.py ä¸­çš„å›ºå®šå­—æ®µä¿æŒä¸€è‡´ï¼‰
    HIGH_FREQ_FIELDS = ["source", "title", "category",
                        "data_type", "platform", "crawled_at"]

    def _extract_metadata(self, item: Dict, source: str) -> Dict:
        """
        ä»å­—å…¸æ•°æ®ä¸­æå– metadata

        é«˜é¢‘å­—æ®µæ”¾å…¥å¯¹åº” keyï¼Œå…¶ä»–å­—æ®µä¹Ÿæ”¾å…¥ metadataï¼ˆåŠ¨æ€å­—æ®µï¼‰ï¼Œ
        è‡ªåŠ¨æ³¨å…¥ crawled_at æ—¶é—´æˆ³ã€‚
        """
        from datetime import datetime
        metadata = {}

        # æ³¨å…¥é«˜é¢‘å­—æ®µï¼ˆæœ‰åˆ™å–å€¼ï¼Œæ— åˆ™ç•™ç©ºè®© Schema é»˜è®¤å€¼å¤„ç†ï¼‰
        metadata["source"] = item.get("source", source)
        metadata["title"] = item.get("title", item.get("name", ""))
        metadata["category"] = item.get("category", item.get("type", ""))
        metadata["data_type"] = item.get("data_type", "crawled")
        metadata["platform"] = item.get("platform", "")
        metadata["crawled_at"] = item.get(
            "crawled_at", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

        # å…¶ä»–å­—æ®µä¹Ÿæ”¾å…¥ metadataï¼ˆåˆ©ç”¨ Milvus åŠ¨æ€å­—æ®µï¼‰
        for key, value in item.items():
            if key not in self.HIGH_FREQ_FIELDS and key not in ("text", "content", "page_content"):
                # åªå­˜æ ‡é‡å€¼ï¼Œè·³è¿‡åµŒå¥—ç»“æ„
                if isinstance(value, (str, int, float, bool)):
                    metadata[key] = value

        return metadata

    def _get_text_content(self, item) -> str:
        """
        ä»æ•°æ®ä¸­æå– page_content æ–‡æœ¬

        ä¼˜å…ˆçº§ï¼štext > content > page_content > JSON åºåˆ—åŒ–
        """
        import json
        if isinstance(item, str):
            return item
        if isinstance(item, dict):
            # ä¼˜å…ˆå–ä¸“ç”¨æ–‡æœ¬å­—æ®µ
            for key in ("text", "content", "page_content", "description", "summary"):
                if key in item and item[key]:
                    return str(item[key])
            # æ²¡æœ‰ä¸“ç”¨å­—æ®µï¼Œåºåˆ—åŒ–æ•´ä¸ª dict
            return json.dumps(item, ensure_ascii=False, indent=2)
        return str(item)

    def add(self, content: Union[str, Dict, List], source: str = "auto_crawl") -> bool:
        """
        æ·»åŠ å†…å®¹åˆ°ç¼“å†²åŒºï¼ˆéé˜»å¡ï¼‰

        Args:
            content: æ–‡æœ¬å†…å®¹ã€å­—å…¸æˆ–å­—å…¸åˆ—è¡¨
            source: æ•°æ®æ¥æºæ ‡è¯†

        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ å…¥ç¼“å†²
        """
        from langchain_core.documents import Document
        from rag.field_registry import register_fields
        from datetime import datetime

        try:
            # ç»Ÿä¸€è½¬æ¢ä¸ºåˆ—è¡¨
            items = []
            if isinstance(content, str):
                items = [content]
            elif isinstance(content, dict):
                items = [content]
            elif isinstance(content, list):
                items = content

            docs = []
            all_field_names = set()

            for item in items:
                # æå–æ–‡æœ¬ï¼ˆå†…å®¹ï¼‰
                text = self._get_text_content(item)
                if len(text) < 10:
                    continue
                if len(text) > self.MAX_CONTENT_LENGTH:
                    text = text[:self.MAX_CONTENT_LENGTH] + "...[æˆªæ–­]"

                # æ„å»º metadata
                if isinstance(item, dict):
                    metadata = self._extract_metadata(item, source)
                    all_field_names.update(metadata.keys())
                else:
                    metadata = {
                        "source": source,
                        "title": "",
                        "category": "",
                        "data_type": "crawled",
                        "platform": "",
                        "crawled_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    }

                docs.append(Document(page_content=text, metadata=metadata))

            if not docs:
                return False

            # æ³¨å†Œå­—æ®µåˆ°æ³¨å†Œè¡¨
            if all_field_names:
                register_fields(list(all_field_names))

            with self.lock:
                self.buffer.extend(docs)
                buffer_size = len(self.buffer)

            print(
                f"ğŸ“¥ [KB] å·²åŠ å…¥ç¼“å†² ({buffer_size} æ¡å¾…å†™å…¥, å­—æ®µ: {len(all_field_names)} ä¸ª)")

            # è¾¾åˆ°é˜ˆå€¼è‡ªåŠ¨åˆ·æ–°
            if buffer_size >= self.BUFFER_THRESHOLD:
                self.flush_async()

            return True

        except Exception as e:
            print(f"âŒ [KB] æ·»åŠ å¤±è´¥: {e}")
            return False

    def flush_async(self) -> Optional[Future]:
        """
        å¼‚æ­¥åˆ·æ–°ç¼“å†²åŒºï¼ˆéé˜»å¡ï¼‰

        Returns:
            Future: å¼‚æ­¥ä»»åŠ¡å¥æŸ„ï¼Œå¯ç”¨äºç­‰å¾…å®Œæˆ
        """
        with self.lock:
            if not self.buffer:
                return None
            docs_to_save = self.buffer.copy()
            self.buffer.clear()

        print(f"ğŸš€ [KB] å¼‚æ­¥å†™å…¥ {len(docs_to_save)} æ¡æ•°æ®...")
        future = self.executor.submit(self._save_batch, docs_to_save)
        self.pending_futures.append(future)

        # æ¸…ç†å·²å®Œæˆçš„ Future
        self.pending_futures = [
            f for f in self.pending_futures if not f.done()]

        return future

    def _save_batch(self, docs: List) -> bool:
        """æ‰¹é‡å†™å…¥ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        try:
            from skills.vector_gateway import add_documents
            self._ensure_connection()
            add_documents(self._vector_store, docs, tag="KnowledgeBaseManager")
            print(f"   âœ… [KB] æˆåŠŸå†™å…¥ {len(docs)} æ¡æ•°æ®")
            return True
        except Exception as e:
            print(f"   âŒ [KB] æ‰¹é‡å†™å…¥å¤±è´¥: {e}")
            return False

    def flush_and_wait(self, timeout: float = 30.0) -> bool:
        """
        åŒæ­¥åˆ·æ–°å¹¶ç­‰å¾…æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡å®Œæˆï¼ˆç¨‹åºé€€å‡ºæ—¶è°ƒç”¨ï¼‰

        Args:
            timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            bool: æ˜¯å¦å…¨éƒ¨å®Œæˆ
        """
        print("â³ [KB] æ­£åœ¨åˆ·æ–°ç¼“å†²åŒºå¹¶ç­‰å¾…æ‰€æœ‰å†™å…¥å®Œæˆ...")

        # å…ˆåˆ·æ–°å½“å‰ç¼“å†²
        self.flush_async()

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        from concurrent.futures import wait, FIRST_EXCEPTION

        if self.pending_futures:
            done, not_done = wait(self.pending_futures, timeout=timeout)

            if not_done:
                print(f"   âš ï¸ [KB] {len(not_done)} ä¸ªä»»åŠ¡è¶…æ—¶æœªå®Œæˆ")
                return False

            # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸
            for future in done:
                try:
                    future.result()
                except Exception as e:
                    print(f"   âŒ [KB] ä»»åŠ¡å¼‚å¸¸: {e}")

        print("   âœ… [KB] æ‰€æœ‰å†™å…¥ä»»åŠ¡å·²å®Œæˆ")
        return True

    def _cleanup(self):
        """ç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†ï¼ˆatexit å›è°ƒï¼‰"""
        print("\nğŸ”„ [KB] ç¨‹åºé€€å‡ºï¼Œæ­£åœ¨æ¸…ç†...")
        self.flush_and_wait(timeout=10.0)
        self.executor.shutdown(wait=False)


# ==================== å…¨å±€å•ä¾‹ ====================
kb_manager = KnowledgeBaseManager()


# ==================== ä¾¿æ·å‡½æ•°ï¼ˆå‘åå…¼å®¹ï¼‰====================

def ask_knowledge_base(question: str) -> str:
    """
    [RAG] æŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“ã€‚

    Args:
        question (str): ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜ï¼ˆå®Œæ•´é—®é¢˜ï¼Œå†…éƒ¨å¤„ç†åˆ†æï¼‰ã€‚

    Returns:
        str: çŸ¥è¯†åº“çš„å›ç­”ã€‚
    """
    print(f"ğŸ“š [RAG] æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“: {question}")

    try:
        from rag.retriever_qa import qa_interaction
        answer = qa_interaction(question)
        return answer
    except ImportError as e:
        return f"Error: RAG æ¨¡å—æœªæ‰¾åˆ°æˆ–å¯¼å…¥å¤±è´¥ã€‚{e}"
    except Exception as e:
        return f"Error: æŸ¥è¯¢çŸ¥è¯†åº“æ—¶å‡ºé”™: {e}"


def save_to_knowledge_base(content: str, source: str = "auto_web_spider") -> bool:
    """
    [RAG] å°†å†…å®¹ä¿å­˜åˆ°çŸ¥è¯†åº“ï¼ˆå¼‚æ­¥éé˜»å¡ï¼‰

    Args:
        content: æ–‡æœ¬å†…å®¹
        source: æ•°æ®æ¥æº

    Returns:
        bool: æ˜¯å¦æˆåŠŸåŠ å…¥ç¼“å†²
    """
    return kb_manager.add(content, source)
