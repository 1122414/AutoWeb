import json
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from core.state import AgentState
from config import MODEL_NAME, OPENAI_API_KEY, OPENAI_BASE_URL
from skills.observer import BrowserObserver

class PlannerAgent:
    def __init__(self, observer: BrowserObserver):
        self.observer = observer
        self.llm = ChatOpenAI(
            model=MODEL_NAME,
            temperature=0,
            openai_api_key=OPENAI_API_KEY,
            openai_api_base=OPENAI_BASE_URL,
            
        )

    def run(self, state: AgentState, browser_tab):
        """
        æ‰§è¡Œè§„åˆ’é€»è¾‘
        """
        print("\nğŸ§  [Planner] æ­£åœ¨åˆ¶å®šè®¡åˆ’...")
        
        task = state["user_task"]
        loop_count = state.get("loop_count", 0)
        
        # [Lazy Planning Strategy]
        # å¦‚æœæ˜¯ç¬¬ä¸€æ­¥ (Step 0)ï¼Œé€šå¸¸åªæ˜¯éœ€è¦ä¸€ä¸ªå¯¼èˆªåŠ¨ä½œï¼Œä¸éœ€è¦åˆ†æ DOM
        # è¿™æ ·å¯ä»¥æ˜¾è‘—èŠ‚çœ Token å¹¶åŠ å¿«å¯åŠ¨é€Ÿåº¦
        if loop_count == 0:
            print("   â© [Planner] åˆå§‹å¯åŠ¨ï¼Œè·³è¿‡ DOM åˆ†æï¼Œç›´æ¥ç”Ÿæˆå¯¼èˆªè®¡åˆ’ã€‚")
            dom = "(Start Page - Empty)"
            suggestions_str = "(æ—  - åˆå§‹å¯¼èˆªé˜¶æ®µ)"
            prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªç½‘é¡µè‡ªåŠ¨åŒ–è§„åˆ’ä¸“å®¶ã€‚
            
            ã€ç”¨æˆ·ä»»åŠ¡ã€‘
            {task}
            
            ã€å½“å‰çŠ¶æ€ã€‘
            æµè§ˆå™¨åˆšå¯åŠ¨ï¼Œå¤„äºç©ºç™½é¡µ/åˆå§‹é¡µã€‚
            
            è¯·ç›´æ¥åˆ¶å®š**ç¬¬ä¸€æ­¥**è®¡åˆ’ï¼ˆé€šå¸¸æ˜¯æ‰“å¼€ç›®æ ‡ç½‘å€ï¼‰ã€‚
            
            å›å¤æ ¼å¼ï¼š
            ã€è®¡åˆ’å·²ç”Ÿæˆã€‘
            1. æ‰“å¼€ç½‘å€ https://...
            """
            
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return {
                "messages": [response],
                "plan": response.content,
                "dom_skeleton": dom,
                "loop_count": loop_count + 1,
                "is_complete": False
            }

        # 1. æ„ŸçŸ¥ç¯å¢ƒ (Observer)
        try:
            # æ•è· DOM (é™åˆ¶é•¿åº¦é˜²æ­¢ Token æº¢å‡º)
            dom = self.observer.capture_dom_skeleton(browser_tab)[:30000] 
            
            # ã€é€‚é…é‡ç‚¹ã€‘è°ƒç”¨è§†è§‰åˆ†æï¼Œè·å–å®šä½å»ºè®®åˆ—è¡¨
            # æ³¨æ„ï¼šè¿™é‡Œè¿”å›çš„æ˜¯ List[Dict]ï¼Œä¾‹å¦‚ [{"locator": "#search"}, {"locator": "#btn"}]
            print("   -> æ­£åœ¨è¿›è¡Œè§†è§‰å®šä½åˆ†æ...")
            locator_suggestions = self.observer.analyze_locator_strategy(dom, task)
            
            # å°†åˆ—è¡¨åºåˆ—åŒ–ä¸ºæ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿åµŒå…¥ Prompt
            if isinstance(locator_suggestions, list) and locator_suggestions:
                suggestions_str = json.dumps(locator_suggestions, ensure_ascii=False, indent=2)
            else:
                suggestions_str = "æ— ç‰¹å®šå®šä½å»ºè®®ï¼Œè¯·è‡ªè¡Œåˆ†æ DOMã€‚"
                
        except Exception as e:
            dom = f"DOM Capture Failed: {e}"
            suggestions_str = f"è§†è§‰åˆ†æå¤±è´¥: {str(e)}"

        reflections = state.get("reflections", [])
        
        # 2. æ³¨å…¥åæ€è®°å¿†
        reflection_str = ""
        if reflections:
            reflection_str = "\nâš ï¸ **ä¹‹å‰çš„å¤±è´¥æ•™è®­ (è¯·åœ¨è§„åˆ’æ—¶é‡ç‚¹è§„é¿)**:\n" + "\n".join([f"- {r}" for r in reflections])

        finished_steps = state.get("finished_steps", [])
        finished_steps_str = "\n".join([f"- {s}" for s in finished_steps]) if finished_steps else "(æ— )"

        # 3. æ„å»º Prompt
        # æˆ‘ä»¬å°†å»ºè®®åˆ—è¡¨ explicit åœ°å±•ç¤ºç»™ Planner
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªç²¾é€šç½‘é¡µè‡ªåŠ¨åŒ–çš„è§„åˆ’ä¸“å®¶ã€‚ç›®å‰é‡‡ç”¨ã€è¿­ä»£å¼è§„åˆ’ã€‘æ¨¡å¼ã€‚
        
        ã€ç”¨æˆ·æœ€ç»ˆç›®æ ‡ - æ—¶åˆ»ç‰¢è®°ã€‘
        {task}
        
        ã€å·²å®Œæˆæ­¥éª¤ã€‘
        {finished_steps_str}
        
        ã€å½“å‰é¡µé¢ DOM (ç²¾ç®€)ã€‘
        {dom}
        
        ã€è§†è§‰è¾…åŠ©å®šä½å»ºè®® (Visual Suggestions)ã€‘
        {suggestions_str}
        
        {reflection_str}
        
        è¯·åˆ¶å®š**ä¸‹ä¸€æ­¥**çš„è¡ŒåŠ¨è®¡åˆ’ã€‚
        
        ã€è§„åˆ’åŸåˆ™ - æ ¸å¿ƒé“å¾‹ã€‘
        1. **å•æ­¥æ‰§è¡Œ (Atomic Step)**: æ¯æ¬¡**åªèƒ½åˆ¶å®š 1 ä¸ªæ­¥éª¤**ã€‚
           - âŒ é”™è¯¯: "1. ç‚¹å‡»é“¾æ¥ 2. ç­‰å¾…åŠ è½½" (ç¦æ­¢ä¸€æ¬¡æ€§åå‡ºå¤šæ­¥)
           - âœ… æ­£ç¡®: "1. ç‚¹å‡»é“¾æ¥" (ç­‰å¾…å’Œåç»­æ“ä½œç•™ç»™ä¸‹ä¸€è½®)
        2. **è§†è§‰ä¼˜å…ˆ**: ä¼˜å…ˆä½¿ç”¨ Suggestion ä¸­çš„å®šä½ç¬¦ã€‚
        3. **ç›®æ ‡æ ¡å‡†**: ç¡®ä¿è¿™ä¸€æ­¥æ˜¯åœ¨æ¨è¿›ã€ç”¨æˆ·æœ€ç»ˆç›®æ ‡ã€‘ã€‚
        4. **ä»»åŠ¡ç»ˆç»“**: åªæœ‰å½“ç›®æ ‡å½»åº•è¾¾æˆæ—¶ï¼Œè¾“å‡º "ã€ä»»åŠ¡å·²å®Œæˆã€‘"ã€‚

        å›å¤æ ¼å¼è¦æ±‚ï¼š
        å¦‚æœä¸ç»“æŸï¼Œå¿…é¡»åŒ…å« "ã€è®¡åˆ’å·²ç”Ÿæˆã€‘" å­—æ ·ï¼Œä¸”**åªæœ‰ä¸€è¡Œè®¡åˆ’**ã€‚
        å¦‚æœç»“æŸï¼Œå¿…é¡»åŒ…å« "ã€ä»»åŠ¡å·²å®Œæˆã€‘" å­—æ ·ã€‚
        
        Example Output 1 (Next Step):
        ã€è®¡åˆ’å·²ç”Ÿæˆã€‘
        1. ç‚¹å‡»å·¦ä¾§å¯¼èˆªæ çš„ "ç”µå½±" é“¾æ¥ (a[href="/vod..."])ã€‚
        
        Example Output 2 (Finished):
        ã€ä»»åŠ¡å·²å®Œæˆã€‘
        æ‰€æœ‰æ•°æ®æŠ“å–å®Œæ¯•å¹¶å·²ä¿å­˜ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        is_finished = "ã€ä»»åŠ¡å·²å®Œæˆã€‘" in response.content
        
        return {
            "messages": [response],
            "plan": response.content,
            "dom_skeleton": dom,
            "locator_suggestions": suggestions_str, # [Optimization] å°†æ„ŸçŸ¥ç»“æœå­˜å…¥ State
            "loop_count": state.get("loop_count", 0) + 1,
            "is_complete": is_finished
        }