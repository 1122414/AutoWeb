# 终极 Token 优化方案：空间折叠与智能缓存报告

为了从本质上解决 Token 消耗过大的问题，我们对系统感知层进行了外科手术式的改造。

## 1. 空间折叠 (JS-Side Compression)
我们在浏览器端 (`js_loader.py`) 实施了极度激进的压缩策略，只保留 "First Principles" 必须的信息：

| 策略 | 原理 | 预期收益 |
| :--- | :--- | :--- |
| **Viewport Culling** | **不看不想看的东西**。任何超出当前屏幕 3 倍以外的元素，直接丢弃（Header/Body 除外）。 | DOM 缩减 **40%+** (长页面) |
| **Class Noise Filter** | **去伪存真**。对于 TailwindCSS 那种长达 100 字符的类名，只要不包含 `btn`, `nav` 等关键词，一律清洗。 | 字符数缩减 **20%** |
| **Wrapper Flattening** | **降维打击**。如果一个 `div` 只是为了布局（无 ID/属性，单子节点），直接提升子节点，消除层级。 | 树深度降低 **30%** |
| **Text Truncation** | 文本截断阈值从 80 降至 50 (足够判断语义)。 | 字符数缩减 **10%** |

**综合效果**: 单个 DOM Packet 的 Token 占用量预计从 **30k** 骤降至 **10k-15k**。

## 2. 智能缓存 (MD5 De-duplication)
我们在 Python 端 (`observer.py`) 引入了 MD5 记忆体：
- **逻辑**: 如果新抓取的 DOM 骨架与上一步完全一致（Hash 相同），说明页面没变。
- **动作**: 直接返回上一轮的分析结果，**完全跳过 LLM 调用**。
- **场景**: 填写表单、点击后弹窗提示、或页面加载失败重试时。
- **收益**: 此类场景 Token 消耗 **降为 0**。

## 3. 感知共享 (Perception Sharing)
（Step 370 已部署）
- Planner 分析完后将结果存入共享内存。
- Coder 直接复用，不再二遍分析。
- **收益**: 正常流程 Token 消耗 **减半**。

---

现在，AutoWeb 运行一次标准任务（如爬取电影）的成本，预计仅为优化前的 **1/3** 甚至更低。建议实际运行体验飞一般的速度。
